{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "working.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPoUPAgPEuR7LviRNRa/dF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnTaco93/IMS_training/blob/main/IMS_TRAINING_MINI_PROJECT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av-68qwJP6RX",
        "outputId": "e4ddc825-ed9b-4b42-d634-98cfad79e5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#%% Change to the root directory\n",
        "# Example:\n",
        "#os.chdir(\"C:/Users/Desktop/LAMDATA\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C76UV34ZQ5gA"
      },
      "source": [
        "# Exercise 2: Data Organization and Feature Extraction\n",
        "\n",
        "'''\n",
        "Instruction\n",
        " ------------\n",
        "In this exercise, you will learn to \n",
        " \n",
        "1. Load the saved cleaned data files from Exercise 1.\n",
        "2. Create a new vector named “HealthLabel” and label Calibration (healthy) runs as “0”, label Test\n",
        "(faulty) runs as “1”.\n",
        "3. Organize the data into training and testing data sets.\n",
        "    a. Use half of the Calibration data as the training data set.\n",
        "    b. Use the rest of the Calibration data and all of the Test data as the testing data set.\n",
        "4. Separate each run according to “Step Number” and calculate the following summary statistics for each sensor variable to formulate the Training Feature Matrix and Testing Feature Matrix:\n",
        "     a. Mean\n",
        "     b. Standard deviation\n",
        "     c. Maximum\n",
        "     d. Minimum\n",
        "     e. Peak-to-peak\n",
        "5. Save Feature Matrix '''\n",
        "\n",
        "# load libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smp0Q2smVtY-"
      },
      "source": [
        "path_data = \"/content/gdrive/My Drive/colab taco/IMS_training/Exercise2_python_Trainee/data_ex1/\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mKG-Vt-QLqz"
      },
      "source": [
        "# Load cleaned data from Ex1\n",
        "''' depending to the type of input file you may use different libraries \n",
        "hint: pd.read_csv is a good approch however you may try any other library\n",
        "'''\n",
        "# ================= Your Code Here ====================\n",
        "\n",
        "data_c = [None] * 107\n",
        "for line in range(107):\n",
        "    data = pd.read_csv(path_data+'calibration/calibration'+str(line+1)+'.csv',header=None)\n",
        "    data1 = np.array(data.values.tolist())\n",
        "    data_c[line] = data1\n",
        "    \n",
        "data_t = [None] * 20\n",
        "for line in range(20):\n",
        "    data = pd.read_csv(path_data+'test/test'+str(line+1)+'.csv',header=None)\n",
        "    data1 = np.array(data.values.tolist())\n",
        "    data_t[line] = data1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSDU-lmeQOq_"
      },
      "source": [
        "#Create a Health Label\n",
        "'''Create a vector named \"HealthLabel\" of size 127*1. Label each Calibration\n",
        " run as 0 and Test run as 1.'''\n",
        " # ================= Your Code Here ====================\n",
        "HealthLabel= [0] * 127\n",
        "HealthLabel[107:]=[1]*20"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeFy9qlkQReP"
      },
      "source": [
        "# Organize Data into Training and Testing\n",
        "''' Re-arrange the Calibration and Test cell arrays into Training and Testing\n",
        "cell arrays. Training cell array should contain half of the Calibration\n",
        " cells, while Testing cell array should contain the other half of the\n",
        "Calibration cells and all of the Test cells. Arrange the health labels in\n",
        "the same fashion. The resulting health label should correspond to each\n",
        "training and testing cell and reflect its groud truth health status.\n",
        "The four variables below will be the variable to store the training and\n",
        "'''\n",
        "TrainData = [None]*(107//2)\n",
        "TestData = [None]*(107//2+1+20)\n",
        "TrainLabel = [None]*(107//2)\n",
        "TestLabel = [None]*(107//2+1+20)\n",
        "\n",
        "# ================= Your Code Here ====================\n",
        "TrainData=data_c[:107//2]\n",
        "TestData[:107//2+1]=data_c[:107//2+1]\n",
        "TestData[107//2+1:]=data_t.copy()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-3M3t_uYnJA"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neGvvFZ8QVyo"
      },
      "source": [
        "# Stepwise Feature Extraction\n",
        "''' 1. For one run, use the variable Step Number to identify which step it is\n",
        "2. For a particular step in this run, calculate the following summary \n",
        "statistics for each sensor signal as a feature\n",
        "      a. Mean\n",
        "       b. Standard deviation\n",
        "       c. Maximum\n",
        "       d. Minimum\n",
        "       e. Peak-to-peak\n",
        " 3. Do this for all the steps\n",
        " 4. Loop through all the runs for both training and testing cell arrays\n",
        " 5. Name each feature while calculating them with \"Step#.VariableName.FeatureName\"\n",
        " 6. The resulting variables will be \n",
        "       a. A training feature matrix of size 53*190 (or 54*190)\n",
        "       b. A feature context string vector of size 190*1\n",
        "       c. A testing feature matrix of size 74*190 (73*190)\n",
        "\n",
        "Below are the variables you need to construct\n",
        "TrainFeature = [];\n",
        "TestFeature = [];\n",
        "FeaContext = [];\n",
        "\n",
        "Example for one run (one possible way of doing this):\n",
        "FeatureName = {'Mean';'Stdev';'Max';'Min';'P2P'};\n",
        "StepNumber = ThisRunData(:,2);\n",
        "for ii = 4:5\n",
        "     Find the index of current step\n",
        "   idx = find(StepNumber == ii);\n",
        "    Get the sensor signal of current step\n",
        "    DataThisStep = ThisRunData(idx,3:end);\n",
        "   for kk = 1:size(DataThisStep,2)\n",
        "         For each sensor reading, calculate the features, \n",
        "         For example, mean\n",
        "        Feature(RunNumber,19*5*(ii-4)+(kk-1)*5+1) = mean(DataThisStep);\n",
        "       FeaContext(19*5*(ii-4)+(kk-1)*5+1,1) = ['Step' num2str(ii) '.' VarName{kk,1} '.' FeatureName{1,1}];\n",
        "         stdev.\n",
        "        Feature(RunNumber,19*5*(ii-4)+(kk-1)*5+2) = std(DataThisStep);\n",
        "       FeaContext(19*5*(ii-4)+(kk-1)*5+2,1) = ['Step' num2str(ii) '.' VarName{kk,1} '.' FeatureName{2,1}];\n",
        "        max\n",
        "         ...\n",
        "         min\n",
        "         ...\n",
        "         p2p\n",
        "         ...\n",
        "    end\n",
        "end'''\n",
        "\n",
        "# ================= Your Code Here ====================\n",
        "\n",
        "\n",
        "#  create feature context\n",
        "var_name=list(pd.read_csv(path_data+'variables.csv',header=None).iloc[:,0])\n",
        "var_name=var_name[2:]\n",
        "FeaContext =np.full([190, 1], None)\n",
        "for run in range(53):\n",
        "  for ii in range(4,6):\n",
        "    idx=np.where(TrainData[run][:,1]==ii)\n",
        "    DataThisStep = TrainData[run][idx,2:][0]\n",
        "    for kk in range(np.shape(TrainData[run][idx,2:][0])[1]):\n",
        "\n",
        "      FeaContext[19*5*(ii-4)+(kk)*5,0]='Step_'+ str(ii)+'_' + var_name[kk]+ '_mean'\n",
        "      FeaContext[19*5*(ii-4)+(kk)*5+1,0]='Step_'+ str(ii)+'_' + var_name[kk]+ '_std'\n",
        "      FeaContext[19*5*(ii-4)+(kk)*5+2,0]='Step_'+ str(ii)+'_' + var_name[kk]+ '_max'\n",
        "      FeaContext[19*5*(ii-4)+(kk)*5+3,0]='Step_'+ str(ii)+'_' + var_name[kk]+ '_min'\n",
        "      FeaContext[19*5*(ii-4)+(kk)*5+4,0]='Step_'+ str(ii)+'_' +var_name[kk]+ '_ptp'\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "# Feature exraction from training data\n",
        "TrainFeature = np.full([53, 190], None)\n",
        "for run in range(53):\n",
        "  for ii in range(4,6):\n",
        "    idx=np.where(TrainData[run][:,1]==ii)\n",
        "    DataThisStep = TrainData[run][idx,2:][0]\n",
        "    for kk in range(np.shape(TrainData[run][idx,2:][0])[1]):\n",
        "      #print(19*5*(ii-4)+(kk)*5)\n",
        "      TrainFeature[run,19*5*(ii-4)+(kk)*5]=np.mean(DataThisStep[kk])\n",
        "      TrainFeature[run,19*5*(ii-4)+(kk)*5+1]=np.std(DataThisStep[kk])\n",
        "      TrainFeature[run,19*5*(ii-4)+(kk)*5+2]=np.max(DataThisStep[kk])\n",
        "      TrainFeature[run,19*5*(ii-4)+(kk)*5+3]=np.min(DataThisStep[kk])\n",
        "      TrainFeature[run,19*5*(ii-4)+(kk)*5+4]=np.ptp(DataThisStep[kk])\n",
        "\n",
        "\n",
        "# feature exraction from test data\n",
        "TestFeature = np.full([74, 190], None)\n",
        "for run in range(74):\n",
        "  for ii in range(4,6):\n",
        "    idx=np.where(TestData[run][:,1]==ii)\n",
        "    DataThisStep = TestData[run][idx,2:][0]\n",
        "    for kk in range(np.shape(TestData[run][idx,2:][0])[1]):\n",
        "      #print(19*5*(ii-4)+(kk)*5)\n",
        "      TestFeature[run,19*5*(ii-4)+(kk)*5]=np.mean(DataThisStep[kk])\n",
        "      TestFeature[run,19*5*(ii-4)+(kk)*5+1]=np.std(DataThisStep[kk])\n",
        "      TestFeature[run,19*5*(ii-4)+(kk)*5+2]=np.max(DataThisStep[kk])\n",
        "      TestFeature[run,19*5*(ii-4)+(kk)*5+3]=np.min(DataThisStep[kk])\n",
        "      TestFeature[run,19*5*(ii-4)+(kk)*5+4]=np.ptp(DataThisStep[kk])\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2oKCgmiZNAj"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJUeNoc_Qt9Q",
        "outputId": "23448a45-4b76-41d0-b2b3-fae5c74138ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save Features\n",
        "''' Save the extracted feature matrix and its labels into  .csv\n",
        " files called \"TrainFeatures.csv, TestFeatures.csv,TrainLabels.csv,testLabels.csv \n",
        " hint: you may use pd.DataFrame for saving files as .CSV'''\n",
        "# ================= Your Code Here ====================\n",
        "TrainFeatures=pd.DataFrame(TrainFeature)\n",
        "TestFeatures=pd.DataFrame(TestFeature)\n",
        "TrainLabels=pd.DataFrame(HealthLabel[:53])\n",
        "TestLabels=pd.DataFrame(HealthLabel[53:])\n",
        "\n",
        "print('Shape of the generated dataframes:')\n",
        "print(TrainFeatures.shape, TestFeatures.shape)\n",
        "\n",
        "path_data_output = \"/content/gdrive/My Drive/colab taco/IMS_training/Exercise2_python_Trainee/data_ex2_output/\"\n",
        "TrainFeatures.to_csv(path_data_output+'TrainFeatures.csv',index=False,header=False)\n",
        "TestFeatures.to_csv(path_data_output+'TestFeatures.csv',index=False,header=False)\n",
        "TrainLabels.to_csv(path_data_output+'TrainLabels.csv',index=False,header=False)\n",
        "TestLabels.to_csv(path_data_output+'TestLabels.csv',index=False,header=False)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the generated dataframes:\n",
            "(53, 190) (74, 190)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSXEkverU1d0"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}